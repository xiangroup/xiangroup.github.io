---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

é’Ÿå¿ºï¼Œæ­¦æ±‰ç†å·¥å¤§å­¦è®¡ç®—æœºä¸äººå·¥æ™ºèƒ½å­¦é™¢æ•™æˆï¼Œåšå¯¼ï¼Œæ­¦æ±‰å¤§å­¦å­¦å£«ï¼Œåä¸­ç§‘æŠ€å¤§å­¦åšå£«ï¼Œä½›ç½—é‡Œè¾¾å¤§å­¦å’ŒåŒ—äº¬å¤§å­¦è®¿é—®å­¦è€…ã€‚è‡´åŠ›äºæ™ºèƒ½äº¤é€šç³»ç»Ÿå¤šåª’ä½“ä¿¡æ¯å¤„ç†å’Œç¥ç»å½¢æ€è®¡ç®—ï¼Œä¾æ‰˜å…‰çº¤ä¼ æ„ŸæŠ€æœ¯å›½å®¶å·¥ç¨‹å®éªŒå®¤å§œå¾·ç”Ÿé™¢å£«å›¢é˜Ÿï¼Œä¸»æŒ/éª¨å¹²å‚ä¸å›½å®¶/çœè‡ªç„¶ç§‘å­¦åŸºé‡‘ã€çœé‡ç‚¹ç ”å‘è®¡åˆ’ç­‰çºµå‘é¡¹ç›®10ä½™é¡¹ï¼Œä¸»æŒ500ä¸‡å…ƒé‡å¤§æ¨ªå‘é¡¹ç›®1é¡¹ï¼Œä¸»æŒèµ·è‰çœåœ°æ–¹æ ‡å‡†1é¡¹ã€‚æˆæœèšç„¦è§£å†³å¤æ‚å¤šå˜åœºæ™¯ç›®æ ‡è¯†åˆ«å’Œè¡Œä¸ºç†è§£ç­‰å…³é”®é—®é¢˜ï¼Œåº”ç”¨äºæ­¦æ±‰å¤šä¸ªåŸå¸‚é“è·¯/éš§é“æ™ºèƒ½ç›‘æ§ç³»ç»Ÿï¼Œè‡³2019å¹´åˆ›é€ ç¤¾ä¼šç»æµæ•ˆç›Šè¶…3äº¿å…ƒï¼Œä¸ºæ™ºæ…§åŸå¸‚å»ºè®¾æä¾›æœ‰åŠ›æ”¯æ’‘ã€‚è·çœçº§å¥–åŠ±5é¡¹ï¼Œå‡ºç‰ˆä¸“è‘—5éƒ¨ï¼Œå‘è¡¨é«˜æ°´å¹³è®ºæ–‡100ä½™ç¯‡ï¼Œå…¶ä¸­CCF A/SCIä¸€åŒºä»¥ä¸Š10ä½™ç¯‡ï¼Œç”³è¯·/æˆæƒå‘æ˜ä¸“åˆ©13é¡¹ã€‚è·æ ¡é’å¹´æ•™å­¦åå¸ˆï¼ŒæŒ‡å¯¼å­¦ç”Ÿåœ¨å›½é™…æ——èˆ°ä¼šè®®ICMEæŒ‘æˆ˜èµ›è·å† å†›ï¼Œäº’è”ç½‘+å¤§èµ›è·çœé“¶å¥–ï¼Œä¸­å›½è½¯ä»¶æ¯å¤§èµ›è·å…¨å›½ä¸‰ç­‰å¥–ã€‚ä»»CCFé«˜çº§ä¼šå‘˜ï¼ŒCCF YOCSEFæ­¦æ±‰ACå§”å‘˜ï¼ŒCCFå¤šåª’ä½“æŠ€æœ¯ä¸“å§”ä¼šæ‰§è¡Œå§”å‘˜ï¼ŒCSIGå¤šåª’ä½“ä¸“å§”ä¼šå’Œäº¤é€šè§†é¢‘ä¸“å§”ä¼šå§”å‘˜ï¼ŒTIPã€TGRSã€TCSVTã€TMMç­‰æœŸåˆŠçš„å®¡ç¨¿äººå’Œå®¢åº§ç¼–è¾‘ï¼ŒAAAIã€ACLã€IJCAIã€ACMMMã€EMNLPã€ICASSPç­‰ä¼šè®®çš„ç¨‹åºå§”å‘˜ä¼šæˆå‘˜ï¼Œçœç§‘åï¼Œçœå•†åŠ¡å…ï¼Œçœå¹¿ç”µå±€ï¼Œå¸‚äº¤ç®¡å±€ï¼Œå›½ç½‘åä¸­ï¼Œçƒ½ç«ä¼—æ™ºç­‰æœºæ„çš„å’¨è¯¢è¯„å®¡ä¸“å®¶ã€‚

ç ”ç©¶é¢†åŸŸï¼šäººå·¥æ™ºèƒ½ã€å¤šåª’ä½“ä¿¡æ¯å¤„ç†ã€ç¥ç»å½¢æ€è®¡ç®—.


# ğŸ’»ï¸ Research Direction
- å¤šåª’ä½“é™è´¨å¢å¼ºï¼šå›¾åƒå»é›¨ã€å›¾åƒä¿®å¤

-  å¤šåª’ä½“ç›®æ ‡è¯†åˆ«ï¼šç›®æ ‡é‡è¯†åˆ«ã€ç›®æ ‡æœç´¢ã€äººç¾¤è®¡æ•°

- å¤šåª’ä½“åœºæ™¯ç†è§£ï¼šè¯­ä¹‰åˆ†å‰²

- å¤šåª’ä½“è¡Œä¸ºè¯†åˆ«ï¼šè¡Œä¸ºè¯†åˆ«ã€è¡Œä¸ºæ£€æµ‹ã€è½¨è¿¹é¢„æµ‹

- è·¨åª’ä½“åˆ†æä¸æ£€ç´¢ï¼šè§†é¢‘æè¿°ã€è·¨æ¨¡æ€æ£€ç´¢

- ç¥ç»å½¢æ€è®¡ç®—ï¼šè„‰å†²ç¥ç»ç½‘ç»œ


# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibs sit amet](https://github.com), A, B, C, **CVPR 2020**

# ğŸ– Honors And Awards
- Xian Zhong, Cheng Gu, Mang Ye*, Wenxin Huang, Chia-Wen Lin. Graph Complemented Latent Representation for Few-Shot Image Classification. IEEE Trans. Multimedia, 2023, 25: 1979-1990 (CCF BåˆŠ, ä¸­ç§‘é™¢ä¸€åŒºé¡¶åˆŠ, JCR Q1, å½±å“å½±å­7.3)

- Xian Zhong, Xu Yan, Zhengwei Yang, Wenxin Huang*, Kui Jiang, Ryan Wen Liu, Zheng Wang. Visual Exposes You: Pedestrian Trajectory Prediction Meets Visual Intention. IEEE Trans. Intell. Transp. Syst., 2023 (CCF BåˆŠ, ä¸­ç§‘é™¢ä¸€åŒºé¡¶åˆŠ, JCR Q1, å½±å“å› å­8.5)

- Wenxuan Liu, Xian Zhong*, Zhuo Zhou, Kui Jiang, Zheng Wang, Chia-Wen Lin. Dual-Recommendation Disentanglement Network for View Fuzz in Action Recognition. IEEE Trans. Image Process., 2023, 32: 2719-2733 (CCF AåˆŠ, ä¸­ç§‘é™¢ä¸€åŒºé¡¶åˆŠ, JCR Q1, å½±å“å½±å­10.6)

- Zhengwei Yang, Xian Zhong*, Zhun Zhong, Hong Liu, Zheng Wang, Shin'ichi Satoh. Win-Win by Competition: Auxiliary-Free Cloth-Changing Person Re-Identification. IEEE Trans. Image Process., 2023, 32: 2985-2999 (CCF AåˆŠ, ä¸­ç§‘é™¢ä¸€åŒºé¡¶åˆŠ, JCR Q1, å½±å“å½±å­10.6)

- Wenxin Huang, Xuemei Jia, Xian Zhong*, Xiao Wang, Kui Jiang, Zheng Wang. Beyond the Parts: Learning Coarse-to-Fine Adaptive Alignment Representation for Person Search. ACM Trans. Multimedia Comput. Commun. Appl., 2023, 19(3): 105:1-105:19 (CCF BåˆŠ, ä¸­ç§‘é™¢ä¸‰åŒº, JCR Q1, å½±å“å½±å­5.1)

- Xian Zhong, Tianyou Lu, Wenxin Huang*, Mang Ye, Xuemei Jia, Chia-Wen Lin. Grayscale Enhancement Colorization Network for Visible-Infrared Person Re-Identification. IEEE Trans. Circuits Syst. Video Technol., 2022, 32(3): 1418-1430 (é«˜è¢«å¼•è®ºæ–‡, CCF BåˆŠ, ä¸­ç§‘é™¢ä¸€åŒºé¡¶åˆŠ, JCR Q1, å½±å“å½±å­8.4)

- Xuemei Jia, Xian Zhong#, Mang Ye*, Wenxuan Liu, Wenxin Huang. Complementary Data Augmentation for Cloth-Changing Person Re-Identification. IEEE Trans. Image Process. 2022, 31: 4227-4239 (CCF AåˆŠ, ä¸­ç§‘é™¢ä¸€åŒºé¡¶åˆŠ, JCR Q1, å½±å“å½±å­10.6)

- Xian Zhong, Zipeng Li, Shuqin Chen*, Kui Jiang, Chen Chen, Mang Ye. Refined Semantic Enhancement towards Frequency Diffusion for Video Captioning. in Proc. AAAI Conf. Artif. Intell., 2023: 3724-3732 (CCF Aä¼š)

- Huilin Zhu, Jingling Yuan, Xian Zhong*, Zhengwei Yang, Zheng Wang, Shengfeng He. DAOT: Domain-Agnostically Aligned Optimal Transport for Domain-Adaptive Crowd Counting, in Proc. ACM Int. Conf. Multimedia, 2023 (CCF Aä¼š)

- Kui Jiang, Wenxuan Liu, Xian Zhong, Chia-Wen Lin. DAWN: Direction-aware Attention Wavelet Network for Image Deraining, in Proc. ACM Int. Conf. Multimedia, 2023 (CCF Aä¼š)

- Zhengwei Yang, Meng Lin, Xian Zhong, Yu Wu, Zheng Wang*. Good is Bad: Causality Inspired Cloth-debiasing for Cloth-changing Person Re-identification, in Proc. IEEE/CVF Comput. Vis. Pattern Recognit., 2023 (CCF Aä¼š)

- Xian Zhong, Shidong Tu, Xianzheng Ma, Kui Jiang*, Wenxin Huang, Zheng Wang. Rainy WCity: A Real Rainfall Dataset with Diverse Conditions for Semantic Driving Scene Understanding. in Proc. Int. Joint Conf. Artif. Intell., 2022: 1743-1749 (CCF Aä¼š)

- Huilin Zhu, Jingling Yuan, Zhengwei Yang, Xian Zhong*, Zheng Wang:Fine-Grained Fragment Diffusion for Cross Domain Crowd Counting. in Proc. ACM Int. Conf. Multimedia, 2022: 5659-5668 (CCF Aä¼š)

- Xian Zhong, Shilei Zhao, Xiao Wang*, Kui Jiang, Wenxuan Liu, Wenxin Huang, Zheng Wang. Unsupervised Vehicle Search in the Wild: A New Benchmark. in Proc. ACM Int. Conf. Multimedia, 2021: 5316-5325 (CCF Aä¼š)


# ğŸ“– Educations And Occupational History
- 2003è‡³2007, æ­¦æ±‰å¤§å­¦, è®¡ç®—æœºå­¦é™¢, æœ¬ç§‘, å¯¼å¸ˆï¼šé»„ä¼ æ²³
  
- 2007è‡³2009, åä¸­ç§‘æŠ€å¤§å­¦, è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯å­¦é™¢, ç¡•å£«, å¯¼å¸ˆ: å¢ç‚ç”Ÿ
  
- 2009è‡³2013, åä¸­ç§‘æŠ€å¤§å­¦, è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯å­¦é™¢, åšå£«, å¯¼å¸ˆ: å¢ç‚ç”Ÿ
  
- 2013è‡³2014, ä¸­å—æ°‘æ—å¤§å­¦, è®¡ç®—æœºç§‘å­¦å­¦é™¢, è®²å¸ˆ
  
- 2014è‡³2015, æ­¦æ±‰ç†å·¥å¤§å­¦, è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯å­¦é™¢, è®²å¸ˆ
  
- 2014è‡³2017, æ­¦æ±‰ç†å·¥å¤§å­¦, å…‰çº¤ä¼ æ„ŸæŠ€æœ¯å›½å®¶å·¥ç¨‹å®éªŒå®¤, åšå£«å, å¯¼å¸ˆ: å§œå¾·ç”Ÿ
  
- 2015è‡³2021, æ­¦æ±‰ç†å·¥å¤§å­¦, è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯å­¦é™¢, å‰¯æ•™æˆ
  
- 2016è‡³2017, ä½›ç½—é‡Œè¾¾å¤§å­¦, ç”µå­ä¸è®¡ç®—æœºå·¥ç¨‹ç³», è®¿é—®å­¦è€…

- 2021è‡³2022ï¼Œæ­¦æ±‰ç†å·¥å¤§å­¦ï¼Œè®¡ç®—æœºä¸äººå·¥æ™ºèƒ½å­¦é™¢, å‰¯æ•™æˆ

- 2021è‡³2022, åŒ—äº¬å¤§å­¦, ä¿¡æ¯ç§‘å­¦æŠ€æœ¯å­¦é™¢, è®¿é—®å­¦è€…, å¯¼å¸ˆ: é»„é“å†›
  
- 2022è‡³2023, æ­¦æ±‰ç†å·¥å¤§å­¦, ä¿¡æ¯åŒ–åŠå…¬å®¤, å‰¯ä¸»ä»»ï¼ˆæŒ‚ï¼‰

- 2022è‡³ä»Š, æ­¦æ±‰ç†å·¥å¤§å­¦, è®¡ç®—æœºä¸äººå·¥æ™ºèƒ½å­¦é™¢, æ•™æˆ
